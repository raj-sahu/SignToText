{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "signHack",
      "provenance": [],
      "collapsed_sections": [
        "4-nL86mjGsnM"
      ],
      "authorship_tag": "ABX9TyMsUpbS8EkjPcbJao+CgwoQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raj-sahu/SignToText/blob/master/signHack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi6cDXEREjVd",
        "colab_type": "text"
      },
      "source": [
        "# DRIVE **SETUP** \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd2SRzcPEbpb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fcf126e0-3af2-4e7b-ca5a-f0a3858bfd72"
      },
      "source": [
        "from google.colab import drive # import drive from google colab\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "drive.mount(ROOT) "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmj458b7EXAY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "98f58f73-2773-40a9-d67a-0b36bffd49d4"
      },
      "source": [
        "%cd '/content/drive/My Drive/HackSign'\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/HackSign\n",
            "all\t\t     lsa64_preprocessed.zip  __pycache__\n",
            "lsa64_hand_videos    lsa64_raw.zip\t     Sign4Good\n",
            "lsa64_positions.mat  mediapipeModels\t     SignToText4.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BTroKVf2Ahi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://drive.google.com/file/d/1yhfPpI2iJzPXyx4C7MYR6IPZC3YuuYaL/view?usp=sharing "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiVDCeqoFTS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip lsa64_preprocessed.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-nL86mjGsnM",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtGBo6b4K4K1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "80974f0f-0bea-4e79-a491-8ee652fd3eb6"
      },
      "source": [
        "!wget https://github.com/google/mediapipe/blob/master/mediapipe/models/palm_detection.tflite\n",
        "!wget https://github.com/google/mediapipe/tree/master/mediapipe/models/hand_landmark.tflite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-31 22:43:48--  https://github.com/google/mediapipe/blob/master/mediapipe/models/palm_detection.tflite\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘palm_detection.tflite’\n",
            "\n",
            "\rpalm_detection.tfli     [<=>                 ]       0  --.-KB/s               \rpalm_detection.tfli     [ <=>                ]  78.53K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-07-31 22:43:48 (2.90 MB/s) - ‘palm_detection.tflite’ saved [80416]\n",
            "\n",
            "--2020-07-31 22:43:55--  https://github.com/google/mediapipe/tree/master/mediapipe/models/hand_landmark.tflite\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/google/mediapipe/blob/master/mediapipe/models/hand_landmark.tflite [following]\n",
            "--2020-07-31 22:43:55--  https://github.com/google/mediapipe/blob/master/mediapipe/models/hand_landmark.tflite\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘hand_landmark.tflite’\n",
            "\n",
            "hand_landmark.tflit     [ <=>                ]  78.57K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-07-31 22:43:56 (2.54 MB/s) - ‘hand_landmark.tflite’ saved [80459]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGmyTudfcUn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir mediapipeModels\n",
        "!mv palm_detection.tflite ./mediapipeModels/palm_detection.tflite\n",
        "!mv hand_landmark.tflite  ./mediapipeModels/hand_landmark.tflite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWAk53zdcfpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gpqJpdmMi81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls lsa64_hand_videos/ -X "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKUDPB4sWISX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://doc-0o-5g-docs.googleusercontent.com/docs/securesc/9f0456s7r9fdcnmu7t0tniodjolt87v0/1occffc7f59b7o7pc5ci3168frbdnhkm/1596241425000/06778836722188637978/18337363771433511205/1C7k_m2m4n5VzI4lljMoezc-uowDEgIUh?e=download&authuser=0&nonce=0323pmr0vpjqc&user=18337363771433511205&hash=d2g6bk3kt40fnv20sf1gpn71m2t9uc7l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Rz9SWh6ZtCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip lsa64_raw.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxwf5JaWaJk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls all -x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hkoOqxFnTB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "signtoindex={ \n",
        "    \"Accept\": 49,\n",
        "    \"Appear\": 52,\n",
        "    \"Argentina\": 23,\n",
        "    \"Away\": 12,\n",
        "    \"Barbecue\": 44,\n",
        "    \"Bathe\": 57,\n",
        "    \"Birthday\": 29,\n",
        "    \"Bitter\": 18,\n",
        "    \"Born\": 14,\n",
        "    \"Breakfast\": 30,\n",
        "    \"Bright\": 4,\n",
        "    \"Buy\": 58,\n",
        "    \"Call\": 16,\n",
        "    \"Candy\": 45,\n",
        "    \"Catch\": 54,\n",
        "    \"Chewing-gum\": 46,\n",
        "    \"Coin\": 34,\n",
        "    \"Colors\": 6,\n",
        "    \"Copy\": 59,\n",
        "    \"Country\": 25,\n",
        "    \"Dance\": 56,\n",
        "    \"Deaf\": 41,\n",
        "    \"Drawer\": 13,\n",
        "    \"Enemy\": 9,\n",
        "    \"Find\": 63,\n",
        "    \"Food\": 22,\n",
        "    \"Give\": 62,\n",
        "    \"Green\": 2,\n",
        "    \"Help\": 55,\n",
        "    \"Hungry\": 32,\n",
        "    \"Last name\": 26,\n",
        "    \"Learn\": 15,\n",
        "    \"Light-blue\": 5,\n",
        "    \"Man\": 11,\n",
        "    \"Map\": 33,\n",
        "    \"Milk\": 20,\n",
        "    \"Mock\": 28,\n",
        "    \"Music\": 35,\n",
        "    \"Name\": 38,\n",
        "    \"None\": 37,\n",
        "    \"Opaque\": 0,\n",
        "    \"Patience\": 39,\n",
        "    \"Perfume\": 40,\n",
        "    \"Photo\": 31,\n",
        "    \"Realize\": 61,\n",
        "    \"Red\": 1,\n",
        "    \"Red2\": 7,\n",
        "    \"Rice\": 43,\n",
        "    \"Run\": 60,\n",
        "    \"Ship\": 36,\n",
        "    \"Shut down\": 51,\n",
        "    \"Skimmer\": 17,\n",
        "    \"Son\": 10,\n",
        "    \"Spaghetti\": 47,\n",
        "    \"Sweet milk\": 19,\n",
        "    \"Thanks\": 50,\n",
        "    \"To land\": 53,\n",
        "    \"Trap\": 42,\n",
        "    \"Uruguay\": 24,\n",
        "    \"Water\": 21,\n",
        "    \"Where\": 27,\n",
        "    \"Women\": 8,\n",
        "    \"Yellow\": 3,\n",
        "    \"Yogurt\": 48}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVnflhqSn_wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indextosign={idx:sign for (sign,idx) in signtoindex.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQP__FoOo2tE",
        "colab_type": "text"
      },
      "source": [
        "# DATA SPLIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlsLmjRPaJVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv9b0DRBo5ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('all')\n",
        "videos=os.listdir(os.getcwd())\n",
        "for i in range(64):\n",
        "  if os.path.isdir(indextosign[i]) is False:\n",
        "     os.makedirs(indextosign[i])\n",
        "  p=str(i)\n",
        "  if(i<10):\n",
        "    p='0'+p\n",
        "  for file in glob.glob('0'+p+'_*'):\n",
        "    shutil.move(file,indextosign[i])\n",
        "for file in glob.glob('064_*'):\n",
        "  os.remove(file)\n",
        "os.chdir('../')\n",
        "%ls\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7qWjIQ4s-Bk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a885110-4843-4fce-e3b6-3baae9805ce1"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/HackSign'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvu7pk5Mw_n-",
        "colab_type": "text"
      },
      "source": [
        "## MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k80O95FewkYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad27905a-5a5c-4e7f-ddbf-1851f062c749"
      },
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "import cv2\n",
        "import os\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, MaxPooling2D, Reshape, LSTM\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnHqKU9exVVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vid2frames(vid_dir, frame_limit,noofclass):\n",
        "    \"\"\"\n",
        "    Isolate hands and from video and split video into individual frames\n",
        "\n",
        "        PARAMETERS:\n",
        "        vid_dir (str): Directory of videos\n",
        "\n",
        "        frame_limit (int): Maximum number of frames per video\n",
        "\n",
        "        RETURN:\n",
        "        X_train: Training Frames\n",
        "\n",
        "        Y_train: Labels of each frame\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    data = []\n",
        "\n",
        "    labels = os.listdir(vid_dir)[0:noofclass]\n",
        "    print(labels)\n",
        "\n",
        "    for label in labels:\n",
        "        print(\"Processing \", label)\n",
        "        videos = os.listdir(vid_dir+'/'+label)\n",
        "        for vid in videos:\n",
        "            i = 0\n",
        "            cap = cv2.VideoCapture(vid_dir+'/'+label+'/'+vid)\n",
        "            while(cap.isOpened() and i < frame_limit):\n",
        "\n",
        "                ret, frame = cap.read()\n",
        "\n",
        "                if ret == False:\n",
        "                    break\n",
        "\n",
        "                image = frame\n",
        "                result = image.copy()\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "                lower = np.array([41, 156, 49])\n",
        "                upper = np.array([179, 255, 255])\n",
        "\n",
        "                mask = cv2.inRange(image, lower, upper)\n",
        "                result = cv2.bitwise_and(result, result, mask=mask)\n",
        "\n",
        "                result = cv2.resize(result, (256, 256))\n",
        "\n",
        "                data.append([result, label])\n",
        "\n",
        "                i += 1\n",
        "\n",
        "    X_train = []\n",
        "    Y_train = []\n",
        "\n",
        "    for result, label in data:\n",
        "        X_train.append(result)\n",
        "        Y_train.append(label)\n",
        "\n",
        "    return(X_train, Y_train)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbwrk3RnxcRQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "58420e3d-3873-4bac-97e0-2711ee3a916c"
      },
      "source": [
        "No_Class=4\n",
        "X_train, Y_train = vid2frames('./all', 100,No_Class)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Opaque', 'Red', 'Green', 'Yellow']\n",
            "Processing  Opaque\n",
            "Processing  Red\n",
            "Processing  Green\n",
            "Processing  Yellow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptyQphX00F_t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e34a343-f3fb-441a-d66b-d865d2d613a7"
      },
      "source": [
        "encoder = LabelBinarizer()\n",
        "Y_encoded_train =  encoder.fit_transform(Y_train)\n",
        "X_train = np.array(X_train)\n",
        "len(Y_train),Y_encoded_train.shape,X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14748, (14748, 3), (14748, 256, 256, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQs7qlfXx8hr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "bd279c69-6f2d-4466-8b6c-b9100a287456"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (256,256,3)))\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Reshape((16, 16*256)))\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(1,256)))\n",
        "model.add(LSTM(32, return_sequences=True))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(No_Class-1, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 256, 256, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 128, 128, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 16, 4096)          0         \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 16, 64)            1065216   \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 16, 32)            12416     \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 1,474,467\n",
            "Trainable params: 1,474,467\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XmiQ1cA0DGC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "81c3019c-4232-4a71-df98-075aa7a36bfe"
      },
      "source": [
        "model.fit(X_train, Y_encoded_train, epochs=16, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "14748/14748 [==============================] - 76s 5ms/step - loss: 0.0885 - accuracy: 0.9745\n",
            "Epoch 2/16\n",
            " 9152/14748 [=================>............] - ETA: 24s - loss: 0.0317 - accuracy: 0.9903"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-c151e364a4c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_encoded_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNUwJjoFyZ9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " model.save(\"SignToText\"+str(No_Class)+\".h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmuBVr0uA33E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "boundaries = [\n",
        "    ([0, 120, 0], [140, 255, 100]),\n",
        "    ([25, 0, 75], [180, 38, 255])\n",
        "]\n",
        "\n",
        "\n",
        "def handsegment(frame):\n",
        "    lower, upper = boundaries[0]\n",
        "    lower = np.array(lower, dtype=\"uint8\")\n",
        "    upper = np.array(upper, dtype=\"uint8\")\n",
        "    mask1 = cv2.inRange(frame, lower, upper)\n",
        "\n",
        "    lower, upper = boundaries[1]\n",
        "    lower = np.array(lower, dtype=\"uint8\")\n",
        "    upper = np.array(upper, dtype=\"uint8\")\n",
        "    mask2 = cv2.inRange(frame, lower, upper)\n",
        "    mask = cv2.bitwise_or(mask1, mask2)\n",
        "    output = cv2.bitwise_and(frame, frame, mask=mask)\n",
        "    cv2.imshow(\"images\", mask)\n",
        "    cv2.imshow(\"images\", output)\n",
        "    return output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgA9ZbbegTkj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "609cbd87-a472-4da4-8a66-7a458d9d7b05"
      },
      "source": [
        "frame = cv2.imread(\"test.png\")\n",
        "handsegment(frame)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c15223b69718>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhandsegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-8f2fc78f9569>\u001b[0m in \u001b[0;36mhandsegment\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"uint8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mupper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"uint8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmask1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minRange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboundaries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/core/src/arithm.cpp:1726: error: (-215:Assertion failed) ! _src.empty() in function 'inRange'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qozJ7s7Kgds5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}